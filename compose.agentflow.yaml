version: '3.9'
services:
  # uncomment to enable from within compose:
  openaiapi:
    image: localhost/agentflow
    build: ./agentflow
    ports:
      - "8003:8003"
    restart: unless-stopped
    env_file:
      - ./.agentflow.default.env
      - ./.agentflow.env
    depends_on:
      - llmhost
      - embedding-server
      - scraper
    environment:
      - EMBEDDING_URI=http://embedding-server:8000/embeddings
      - SCRAPER_URI=http://scraper:8002/scrape
      - OPENAI_URI=http://llmhost:8000
      - MODEL_NAME=modelname
    command: http://llmhost:8000 http://embedding-server:8000/embeddings http://scraper:8002/scrape modelname -v --prompt-dir=Prompts 

  llmhost:
    image: ghcr.io/ggerganov/llama.cpp:server-cuda
    volumes:
      - /home/tiny/mnt/drive/gguf:/models
    restart: unless-stopped
    command: -m /models/Qwen1.5-32B-Chat-Q4_K_M.gguf --port 8000 --host 0.0.0.0 -ngl 100 -fa --log-disable -c 8192
    ports:
      - "8000:8000"
    devices:
      - nvidia.com/gpu=all

  chat-ui:
    image: localhost/chat-ui
    build: ./chat-ui
    ports:
      - "80:5173"
    restart: unless-stopped
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - mongo-chatui

  embedding-server:
    image: localhost/embedding-server
    build: ./embedding-server
    ports:
      - "8001:8000"
    devices:
      - "nvidia.com/gpu=all"
    restart: unless-stopped

  scraper:
    image: localhost/scraper
    build: ./scraper
    ports:
      - "8002:8002"
    restart: unless-stopped

  mongo-chatui:
    image: mongo:latest
    restart: unless-stopped