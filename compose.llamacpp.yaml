version: '3.9'
services:
  llmhost:
    image: localhost/llama.cpp
    volumes:
      - ${MODEL_DIR}:/models
    # restart: unless-stopped
    command: >
      -m /models/${MODEL_NAME}
      --metrics
      --port 8000
      --host 0.0.0.0
      -ngl 100
      -fa
      -c 8192
      -ts 1,0
      --main-gpu 1
    ports:
      - "8000:8000"
    devices:
      - nvidia.com/gpu=all
    env_file:
      - ./.agentflow.default.env
      - ./.agentflow.env