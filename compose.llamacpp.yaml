version: '3.9'
services:
  openaiapi:
    image: localhost/llama.cpp:server-cuda
    volumes:
      - /home/tiny/mnt/drive/gguf:/models
    ports:
      - "8003:8003"
    restart: unless-stopped
    # command: -m /models/Yi-1.5-9B-Chat-Q8_0.gguf --port 8003 --host 0.0.0.0 -ngl 100 -fa --log-disable -c 8192
    command: -m /models/Meta-Llama-3-8B-Instruct-correct-pre-tokenizer-and-EOS-token-Q8_0.gguf --port 8003 --host 0.0.0.0 -ngl 100 -fa --log-disable -c 8192
    devices:
      - nvidia.com/gpu=all

  chat-ui:
    image: localhost/chat-ui
    build: ./chat-ui
    ports:
      - "80:5173"
    restart: unless-stopped
    depends_on:
      - mongo-chatui
      - openaiapi

  mongo-chatui:
    image: mongo:latest
    restart: unless-stopped