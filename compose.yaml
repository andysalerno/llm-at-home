version: '3.8'
services:
  text-generation-inference:
    image: ghcr.io/huggingface/text-generation-inference:latest
    command: --model-id ${MODEL_ID} --quantize ${QUANTIZATION} --max-total-tokens ${MAX_TOKENS} --max-input-length ${MAX_INPUT} --max-batch-prefill-tokens ${MAX_INPUT} --max-best-of 1 --max-concurrent-requests 2 --validation-workers 1 --max-top-n-tokens 1 --revision ${MODEL_REVISION}
    volumes:
      - ${MODEL_DOWNLOAD_DIR}:/data
    ports:
      - "8080:80"
    devices:
      - "nvidia.com/gpu=all"
    restart: unless-stopped

  chat-ui:
    image: localhost/chat-ui
    ports:
      - "80:5173"
    restart: unless-stopped
    depends_on:
      - mongo-chatui
    networks:
      - internal_network
    environment:
      - "INFER_HOST=http://${HOSTNAME}:5555/"

  embeddings-server:
    image: localhost/embeddings-server
    ports:
      - "8000:8000"
    devices:
      - "nvidia.com/gpu=all"
    restart: unless-stopped

  mongo-chatui:
    image: mongo:latest
    restart: unless-stopped
    networks:
      - internal_network

networks:
  internal_network: