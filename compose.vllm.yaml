version: '3.9'
services:
  llmhost:
    image: vllm/vllm-openai:latest
    volumes:
      - /home/tiny/mnt/drive/.cache/huggingface:/root/.cache/huggingface
    # restart: unless-stopped
    command: --model bjaidi/Phi-3-medium-128k-instruct-GPTQ-8-bit --served-model-name model --max-model-len 8192
    environment:
      CUDA_DEVICE_ORDER=PCI_BUS_ID
    ports:
      - "8000:8000"
    devices:
      - nvidia.com/gpu=all
